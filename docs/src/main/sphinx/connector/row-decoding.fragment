Row decoding
^^^^^^^^^^^^

A decoder is used to map data onto table columns.

The connector contains the following decoders:

* ``raw`` - message is not interpreted; ranges of raw message bytes are mapped to table columns.
* ``csv`` - message is interpreted as comma separated message, and fields are mapped to table columns.
* ``json`` - message is parsed as JSON, and JSON fields are mapped to table columns.
* ``avro`` - message is parsed based on an Avro schema, and Avro fields are mapped to table columns.
* ``protobuf`` - message is parsed based on a Protobuf schema, and Protobuf fields are mapped to table columns.

.. note::

    If no table definition file exists for a table, the ``dummy`` decoder is used,
    which does not expose any columns.

Raw decoder
"""""""""""

The raw decoder supports reading of raw byte-based values from message or key,
and converting it into Trino columns.

For fields, the following attributes are supported:

* ``dataFormat`` - Selects the width of the data type converted.
* ``type`` - Trino data type. See table later min this document for list of
  supported data types.
* ``mapping`` - ``<start>[:<end>]`` - Start and end position of bytes to convert (optional).

The ``dataFormat`` attribute selects the number of bytes converted.
If absent, ``BYTE`` is assumed. All values are signed.

Supported values are:

* ``BYTE`` - one byte
* ``SHORT`` - two bytes (big-endian)
* ``INT`` - four bytes (big-endian)
* ``LONG`` - eight bytes (big-endian)
* ``FLOAT`` - four bytes (IEEE 754 format)
* ``DOUBLE`` - eight bytes (IEEE 754 format)

The ``type`` attribute defines the Trino data type on which the value is mapped.

Depending on the Trino type assigned to a column, different values of dataFormat can be used:

===================================== =======================================
Trino data type                       Allowed ``dataFormat`` values
===================================== =======================================
``BIGINT``                            ``BYTE``, ``SHORT``, ``INT``, ``LONG``
``INTEGER``                           ``BYTE``, ``SHORT``, ``INT``
``SMALLINT``                          ``BYTE``, ``SHORT``
``TINYINT``                           ``BYTE``
``DOUBLE``                            ``DOUBLE``, ``FLOAT``
``BOOLEAN``                           ``BYTE``, ``SHORT``, ``INT``, ``LONG``
``VARCHAR`` / ``VARCHAR(x)``          ``BYTE``
===================================== =======================================

No other types are supported.

The ``mapping`` attribute specifies the range of the bytes in a key or
message used for decoding. It can be one or two numbers separated by a colon (``<start>[:<end>]``).

If only a start position is given:

* For fixed width types, the column will use the appropriate number of bytes for the specified ``dataFormat`` (see above).
* When ``VARCHAR`` value is decoded, all bytes from start position till the end of the message will be used.

If start and end position are given:

* For fixed width types, the size must be equal to number of bytes used by specified ``dataFormat``.
* For ``VARCHAR`` all bytes between start (inclusive) and end (exclusive) are used.

If no ``mapping`` attribute is specified, it is equivalent to setting start position to 0 and leaving end position undefined.

The decoding scheme of numeric data types (``BIGINT``, ``INTEGER``, ``SMALLINT``, ``TINYINT``, ``DOUBLE``) is straightforward.
A sequence of bytes is read from input message and decoded according to either:

* big-endian encoding (for integer types)
* IEEE 754 format for (for ``DOUBLE``).

Length of decoded byte sequence is implied by the ``dataFormat``.

For ``VARCHAR`` data type a sequence of bytes is interpreted according to UTF-8
encoding.

CSV decoder
"""""""""""

The CSV decoder converts the bytes representing a message or key into a
string using UTF-8 encoding and then interprets the result as a CSV
(comma-separated value) line.

For fields, the ``type`` and ``mapping`` attributes must be defined:

* ``type`` - Trino data type. See the following table for a list of supported data types.
* ``mapping`` - The index of the field in the CSV record.

The ``dataFormat`` and ``formatHint`` attributes are not supported and must be omitted.

Table below lists supported Trino types, which can be used in ``type`` and decoding scheme:

+-------------------------------------+--------------------------------------------------------------------------------+
| Trino data type                     | Decoding rules                                                                 |
+=====================================+================================================================================+
| | ``BIGINT``                        | Decoded using Java ``Long.parseLong()``                                        |
| | ``INTEGER``                       |                                                                                |
| | ``SMALLINT``                      |                                                                                |
| | ``TINYINT``                       |                                                                                |
+-------------------------------------+--------------------------------------------------------------------------------+
| ``DOUBLE``                          | Decoded using Java ``Double.parseDouble()``                                    |
+-------------------------------------+--------------------------------------------------------------------------------+
| ``BOOLEAN``                         | "true" character sequence maps to ``true``;                                    |
|                                     | Other character sequences map to ``false``                                     |
+-------------------------------------+--------------------------------------------------------------------------------+
| ``VARCHAR`` / ``VARCHAR(x)``        | Used as is                                                                     |
+-------------------------------------+--------------------------------------------------------------------------------+

No other types are supported.

JSON decoder
""""""""""""

The JSON decoder converts the bytes representing a message or key into a
JSON according to :rfc:`4627`. Note that the message or key *MUST* convert
into a JSON object, not an array or simple type.

For fields, the following attributes are supported:

* ``type`` - Trino data type of column.
* ``dataFormat`` - Field decoder to be used for column.
* ``mapping`` - slash-separated list of field names to select a field from the JSON object.
* ``formatHint`` - Only for ``custom-date-time``.

The JSON decoder supports multiple field decoders, with ``_default`` being
used for standard table columns and a number of decoders for date- and
time-based types.

The following table lists Trino data types, which can be used as in ``type``, and matching field decoders,
which can be specified via ``dataFormat`` attribute.

+-------------------------------------+--------------------------------------------------------------------------------+
| Trino data type                     | Allowed ``dataFormat`` values                                                  |
+=====================================+================================================================================+
| | ``BIGINT``                        | Default field decoder (omitted ``dataFormat`` attribute)                       |
| | ``INTEGER``                       |                                                                                |
| | ``SMALLINT``                      |                                                                                |
| | ``TINYINT``                       |                                                                                |
| | ``DOUBLE``                        |                                                                                |
| | ``BOOLEAN``                       |                                                                                |
| | ``VARCHAR``                       |                                                                                |
| | ``VARCHAR(x)``                    |                                                                                |
+-------------------------------------+--------------------------------------------------------------------------------+
| | ``DATE``                          | ``custom-date-time``, ``iso8601``                                              |
+-------------------------------------+--------------------------------------------------------------------------------+
| | ``TIME``                          | ``custom-date-time``, ``iso8601``, ``milliseconds-since-epoch``,               |
| |                                   | ``seconds-since-epoch``                                                        |
+-------------------------------------+--------------------------------------------------------------------------------+
| | ``TIME WITH TIME ZONE``           | ``custom-date-time``, ``iso8601``                                              |
+-------------------------------------+--------------------------------------------------------------------------------+
| | ``TIMESTAMP``                     | ``custom-date-time``, ``iso8601``, ``rfc2822``,                                |
| |                                   | ``milliseconds-since-epoch``, ``seconds-since-epoch``                          |
+-------------------------------------+--------------------------------------------------------------------------------+
| | ``TIMESTAMP WITH TIME ZONE``      | ``custom-date-time``, ``iso8601``, ``rfc2822``, ``milliseconds-since-epoch``   |
| |                                   | ``seconds-since-epoch``                                                        |
+-------------------------------------+--------------------------------------------------------------------------------+

No other types are supported.

Default field decoder
+++++++++++++++++++++

This is the standard field decoder, supporting all the Trino physical data
types. A field value is transformed under JSON conversion rules into
boolean, long, double or string values. For non-date/time based columns,
this decoder should be used.

Date and time decoders
++++++++++++++++++++++

To convert values from JSON objects into Trino ``DATE``, ``TIME``, ``TIME WITH TIME ZONE``,
``TIMESTAMP`` or ``TIMESTAMP WITH TIME ZONE`` columns, special decoders must be selected using the
``dataFormat`` attribute of a field definition.

* ``iso8601`` - Text based, parses a text field as an ISO 8601 timestamp.
* ``rfc2822`` - Text based, parses a text field as an :rfc:`2822` timestamp.
* ``custom-date-time`` - Text based, parses a text field according to Joda format pattern
                         specified via ``formatHint`` attribute. Format pattern should conform
                         to https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html.
* ``milliseconds-since-epoch`` - Number-based; interprets a text or number as number of milliseconds since the epoch.
* ``seconds-since-epoch`` - Number-based; interprets a text or number as number of milliseconds since the epoch.

For ``TIMESTAMP WITH TIME ZONE`` and ``TIME WITH TIME ZONE`` data types, if timezone information is present in decoded value, it will
be used as Trino value. Otherwise result time zone will be set to ``UTC``.

Avro decoder
""""""""""""

The Avro decoder converts the bytes representing a message or key in
Avro format based on a schema. The message must have the Avro schema embedded.
Trino does not support schemaless Avro decoding.

For key/message, using ``avro`` decoder, the ``dataSchema`` must be defined.
This should point to the location of a valid Avro schema file of the message which needs to be decoded. This location can be a remote web server
(e.g.: ``dataSchema: 'http://example.org/schema/avro_data.avsc'``) or local file system(e.g.: ``dataSchema: '/usr/local/schema/avro_data.avsc'``).
The decoder fails if this location is not accessible from the Trino coordinator node.

For fields, the following attributes are supported:

* ``name`` - Name of the column in the Trino table.
* ``type`` - Trino data type of column.
* ``mapping`` - A slash-separated list of field names to select a field from the Avro schema. If field specified in ``mapping`` does not exist in the original Avro schema, then a read operation returns ``NULL``.

The following table lists the supported Trino types which can be used in ``type`` for the equivalent Avro field types:

===================================== =======================================
Trino data type                       Allowed Avro data type
===================================== =======================================
``BIGINT``                            ``INT``, ``LONG``
``DOUBLE``                            ``DOUBLE``, ``FLOAT``
``BOOLEAN``                           ``BOOLEAN``
``VARCHAR`` / ``VARCHAR(x)``          ``STRING``
``VARBINARY``                         ``FIXED``, ``BYTES``
``ARRAY``                             ``ARRAY``
``MAP``                               ``MAP``
===================================== =======================================

No other types are supported.

Avro schema evolution
+++++++++++++++++++++

The Avro decoder supports schema evolution feature with backward compatibility. With backward compatibility,
a newer schema can be used to read Avro data created with an older schema. Any change in the Avro schema must also be
reflected in Trino's topic definition file. Newly added/renamed fields *must* have a default value in the Avro schema file.

The schema evolution behavior is as follows:

* Column added in new schema:
  Data created with an older schema produces a *default* value when the table is using the new schema.

* Column removed in new schema:
  Data created with an older schema no longer outputs the data from the column that was removed.

* Column is renamed in the new schema:
  This is equivalent to removing the column and adding a new one, and data created with an older schema
  produces a *default* value when table is using the new schema.

* Changing type of column in the new schema:
  If the type coercion is supported by Avro, then the conversion happens. An
  error is thrown for incompatible types.

Protobuf decoder
""""""""""""""""

The Protobuf decoder converts the bytes representing a message or key in
Protobuf formatted message based on a schema.

For key/message, using the ``protobuf`` decoder, the ``dataSchema`` must be
defined. It points to the location of a valid ``proto`` file of the message
which needs to be decoded. This location can be a remote web server,
``dataSchema: 'http://example.org/schema/schema.proto'``,  or local file,
``dataSchema: '/usr/local/schema/schema.proto'``. The decoder fails if the
location is not accessible from the coordinator.

For fields, the following attributes are supported:

* ``name`` - Name of the column in the Trino table.
* ``type`` - Trino data type of column.
* ``mapping`` - slash-separated list of field names to select a field from the
  Protobuf schema. If field specified in ``mapping`` does not exist in the
  original ``proto`` file then a read operation returns NULL.

The following table lists the supported Trino types which can be used in
``type`` for the equivalent Protobuf field types:

===================================== =======================================
Trino data type                       Allowed Protobuf data type
===================================== =======================================
``BOOLEAN``                           ``bool``
``INTEGER``                           ``int32``, ``uint32``, ``sint32``, ``fixed32``, ``sfixed32``
``BIGINT``                            ``int64``, ``uint64``, ``sint64``, ``fixed64``, ``sfixed64``
``DOUBLE``                            ``double``
``REAL``                              ``float``
``VARCHAR`` / ``VARCHAR(x)``          ``string``
``VARBINARY``                         ``bytes``
``ROW``                               ``Message``
``ARRAY``                             Protobuf type with ``repeated`` field
``MAP``                               ``Map``
``TIMESTAMP``                         ``Timestamp``, predefined in ``timestamp.proto``
===================================== =======================================

Protobuf schema evolution
+++++++++++++++++++++++++

The Protobuf decoder supports the schema evolution feature with backward
compatibility. With backward compatibility, a newer schema can be used to read
Protobuf data created with an older schema. Any change in the Protobuf schema
*must* also be reflected in the topic definition file.

The schema evolution behavior is as follows:

* Column added in new schema:
  Data created with an older schema produces a *default* value when the table is using the new schema.

* Column removed in new schema:
  Data created with an older schema no longer outputs the data from the column that was removed.

* Column is renamed in the new schema:
  This is equivalent to removing the column and adding a new one, and data created with an older schema
  produces a *default* value when table is using the new schema.

* Changing type of column in the new schema:
  If the type coercion is supported by Protobuf, then the conversion happens. An error is thrown for incompatible types.

Protobuf limitations
++++++++++++++++++++

* Protobuf specific types like ``any``, ``oneof`` are not supported.
* Protobuf Timestamp has a nanosecond precision but Trino supports
  decoding/encoding at microsecond precision.
