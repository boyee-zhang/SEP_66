name: ci

on:
  push:
    branches:
      - master
  pull_request:
    paths-ignore:
      - 'docs/**'
  repository_dispatch:
    types: [test-with-secrets-command]

defaults:
  run:
    shell: bash --noprofile --norc -euo pipefail {0}

env:
  # An envar that signals to tests we are executing in the CI environment
  CONTINUOUS_INTEGRATION: true
  # allow overriding Maven command
  MAVEN: ./mvnw --offline
  # maven.wagon.rto is in millis, defaults to 30m
  MAVEN_OPTS: "-Xmx512M -XX:+ExitOnOutOfMemoryError -Dmaven.wagon.rto=60000"
  MAVEN_INSTALL_OPTS: "-Xmx3G -XX:+ExitOnOutOfMemoryError -Dmaven.wagon.rto=60000"
  MAVEN_FAST_INSTALL: "-B --strict-checksums -V --quiet -T 1C -DskipTests -Dmaven.source.skip=true -Dair.check.skip-all"
  MAVEN_COMPILE_COMMITS: "-B --strict-checksums --quiet -T 1C -DskipTests -Dmaven.source.skip=true -Dair.check.skip-all=true -Dmaven.javadoc.skip=true --no-snapshot-updates --no-transfer-progress -pl '!:trino-server-rpm'"
  MAVEN_GIB: "-P gib -Dgib.referenceBranch=refs/remotes/origin/${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || github.event.repository.default_branch }}"
  MAVEN_TEST: "-B --strict-checksums -Dmaven.source.skip=true -Dair.check.skip-all --fail-at-end -P gib -Dgib.referenceBranch=refs/remotes/origin/${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || github.event.repository.default_branch }}"
  # Testcontainers kills image pulls if they don't make progress for > 30s and retries for 2m before failing. This means
  # that if an image doesn't download all it's layers within ~2m then any other concurrent pull will be killed because
  # the Docker daemon only downloads 3 layers concurrently which prevents the other pull from making any progress.
  # This value should be greater than the time taken for the longest image pull.
  TESTCONTAINERS_PULL_PAUSE_TIMEOUT: 600
  TEST_REPORT_RETENTION_DAYS: 5
  HEAP_DUMP_RETENTION_DAYS: 14
  # used by actions/cache to retry the download after this time: https://github.com/actions/cache/blob/main/workarounds.md#cache-segment-restore-timeout
  SEGMENT_DOWNLOAD_TIMEOUT_MINS: 5
  CI_SKIP_SECRETS_PRESENCE_CHECKS: ${{ secrets.CI_SKIP_SECRETS_PRESENCE_CHECKS }}

# Cancel previous PR builds.
concurrency:
  # Cancel all workflow runs except latest within a concurrency group. This is achieved by defining a concurrency group for the PR.
  # Non-PR builds have singleton concurrency groups.
  # When triggered by the repository_dispatch, add the expected SHA to avoid cancelling the run from the PR.
  group: |
    workflow=${{ github.workflow }},
    pr_number=${{ github.event_name == 'pull_request' && github.event.number || 'NA' }},
    dispatch_sha=${{ github.event_name == 'repository_dispatch' && github.event.client_payload.slash_command.args.named.sha || 'NA' }},
    commit_sha=${{ github.event_name != 'pull_request' && github.event_name != 'repository_dispatch' && github.sha || 'NA' }}
  cancel-in-progress: true

jobs:
  build-pt:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      product-tests-changed: ${{ steps.filter.outputs.product-tests }}
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # checkout all commits to be able to determine merge base for GIB
          ref: |
            ${{ github.event_name == 'repository_dispatch' &&
                github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha &&
                format('refs/pull/{0}/head', github.event.client_payload.pull_request.number) || '' }}
      - uses: ./.github/actions/setup
        with:
          cache: restore
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            product-tests:
              - 'testing/trino-product-tests*/**'
              - 'testing/trino-testing-services/**'
              # run all tests when there are any changes in the trino-server Maven module
              # because it doesn't define it's Trino dependencies and
              # it relies on the Provisio plugin to find the right artifacts
              - 'core/trino-server/**'
              - '.github/**'
      - name: Maven Install
        run: |
          export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"
          $MAVEN clean install ${MAVEN_FAST_INSTALL} -pl '!:trino-docs,!:trino-server-rpm'
      - name: Map impacted plugins to features
        run: |
          export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"
          # build a list of impacted modules, ignoring modules that cannot affect either product tests or Trino
          $MAVEN validate ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -Dgib.logImpactedTo=gib-impacted.log -pl '!:trino-docs,!:trino-tests,!:trino-faulttolerant-tests'
          # GIB doesn't run on master, so make sure the file always exist
          touch gib-impacted.log
          testing/trino-plugin-reader/target/trino-plugin-reader-*-executable.jar -i gib-impacted.log -p core/trino-server/target/trino-server-*-hardlinks/plugin > impacted-features.log
          echo "Impacted plugin features:"
          cat impacted-features.log
      - name: Product tests artifact
        uses: actions/upload-artifact@v3
        with:
          name: product tests and server tarball
          path: |
            core/trino-server/target/*.tar.gz
            impacted-features.log
            testing/trino-product-tests-launcher/target/*.jar
            testing/trino-product-tests/target/*-executable.jar
            client/trino-cli/target/*-executable.jar
          retention-days: 1
      - id: prepare-matrix-template
        run: |
          cat <<EOF > .github/test-pt-matrix.yaml
          config:
            - default
            - hdp3
            # TODO: config-apache-hive3
          suite:
            - suite-1
            - suite-2
            - suite-3
            # suite-4 does not exist
            - suite-5
            - suite-azure
            - suite-delta-lake-databricks73
            - suite-delta-lake-databricks91
            - suite-delta-lake-databricks104
            - suite-delta-lake-databricks113
            - suite-delta-lake-databricks122
            - suite-gcs
            - suite-clients
            - suite-functions
            - suite-tpch
            - suite-storage-formats-detailed
          exclude:
            - config: default
              ignore exclusion if: >-
                ${{ github.event_name != 'pull_request'
                 || github.event.pull_request.head.repo.full_name == github.repository
                 || contains(github.event.pull_request.labels.*.name, 'tests:all')
                 || contains(github.event.pull_request.labels.*.name, 'tests:hive')
                 }}

            - suite: suite-azure
              config: default
            - suite: suite-azure
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' ||
                    secrets.AZURE_ABFS_CONTAINER != '' ||
                    secrets.AZURE_ABFS_ACCOUNT != '' ||
                    secrets.AZURE_ABFS_ACCESSKEY != '' }}

            - suite: suite-gcs
              config: default
            - suite: suite-gcs
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || secrets.GCP_CREDENTIALS_KEY != '' }}

            - suite: suite-delta-lake-databricks73
              config: hdp3
            - suite: suite-delta-lake-databricks73
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || secrets.DATABRICKS_TOKEN != '' }}
            - suite: suite-delta-lake-databricks91
              config: hdp3
            - suite: suite-delta-lake-databricks91
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || secrets.DATABRICKS_TOKEN != '' }}
            - suite: suite-delta-lake-databricks104
              config: hdp3
            - suite: suite-delta-lake-databricks104
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || secrets.DATABRICKS_TOKEN != '' }}
            - suite: suite-delta-lake-databricks113
              config: hdp3
            - suite: suite-delta-lake-databricks113
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || secrets.DATABRICKS_TOKEN != '' }}
            - suite: suite-delta-lake-databricks122
              config: hdp3
            - suite: suite-delta-lake-databricks122
              ignore exclusion if: >-
                ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || secrets.DATABRICKS_TOKEN != '' }}

          ignore exclusion if:
            # Do not use this property outside of the matrix configuration.
            #
            # This is added to all matrix entries so they may be conditionally
            # excluded by adding them to the excludes list with a GHA expression
            # for this property.
            # - If the expression evaluates to true, it will never match the a
            #   actual value of the property, and will therefore not be excluded.
            # - If the expression evaluates to false, it will match the actual
            #   value of the property, and the exclusion will apply normally.
            - "false"
          include:
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-6-non-generic
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-7-non-generic
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-8-non-generic
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-tpcds
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-parquet
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-oauth2
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-ldap
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-compatibility
            # this suite is designed specifically for apache-hive3. TODO remove the suite once we can run all regular tests on apache-hive3.
            - config: apache-hive3
              suite: suite-hms-only
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-all-connectors-smoke
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-delta-lake-oss
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-kafka
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-cassandra
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-clickhouse
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-mysql
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-iceberg
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-hudi
            # this suite is not meant to be run with different configs
            - config: default
              suite: suite-ignite
          EOF
      - name: Build PT matrix (all)
        if: |
          github.event_name != 'pull_request' ||
          steps.filter.outputs.product-tests == 'true' ||
          contains(github.event.pull_request.labels.*.name, 'tests:all') ||
          contains(github.event.pull_request.labels.*.name, 'tests:all-product')
        run: |
          # converts entire YAML file into JSON - no filtering since we want all PTs to run
          ./.github/bin/build-pt-matrix-from-impacted-connectors.py -v -m .github/test-pt-matrix.yaml -o matrix.json
      - name: Build PT matrix (impacted-features)
        if: |
          github.event_name == 'pull_request' &&
          steps.filter.outputs.product-tests == 'false' &&
          !contains(github.event.pull_request.labels.*.name, 'tests:all') &&
          !contains(github.event.pull_request.labels.*.name, 'product-tests:all')
        # all these envs are required to be set by some product test environments
        env:
          ABFS_CONTAINER:
          ABFS_ACCOUNT:
          ABFS_ACCESS_KEY:
          S3_BUCKET:
          AWS_REGION:
          TRINO_AWS_ACCESS_KEY_ID:
          TRINO_AWS_SECRET_ACCESS_KEY:
          DATABRICKS_73_JDBC_URL:
          DATABRICKS_91_JDBC_URL:
          DATABRICKS_104_JDBC_URL:
          DATABRICKS_113_JDBC_URL:
          DATABRICKS_122_JDBC_URL:
          DATABRICKS_LOGIN:
          DATABRICKS_TOKEN:
          GCP_CREDENTIALS_KEY:
          GCP_STORAGE_BUCKET:
          TESTCONTAINERS_NEVER_PULL: true
        run: |
          # converts filtered YAML file into JSON
          ./.github/bin/build-pt-matrix-from-impacted-connectors.py -v -m .github/test-pt-matrix.yaml -i impacted-features.log -o matrix.json
      - id: set-matrix
        run: |
          echo "Matrix: $(jq '.' matrix.json)"
          echo "matrix=$(cat matrix.json)" >> $GITHUB_OUTPUT

  pt:
    runs-on: ubuntu-latest
    # explicitly define the name to avoid adding the value of the `ignore exclusion if` matrix item
    name: pt (${{ matrix.config }}, ${{ matrix.suite }}, ${{ matrix.jdk }})
    if: needs.build-pt.outputs.matrix != '{}'
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.build-pt.outputs.matrix) }}
    # PT Launcher's timeout defaults to 2h, add some margin
    timeout-minutes: 130
    needs: build-pt
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # checkout all commits, as the build result depends on `git describe` equivalent
          ref: |
            ${{ github.event_name == 'repository_dispatch' &&
                github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha &&
                format('refs/pull/{0}/head', github.event.client_payload.pull_request.number) || '' }}
      - uses: ./.github/actions/setup
        with:
          cache: false
          download_dependencies: false
      - name: Product tests artifact
        uses: actions/download-artifact@v3
        with:
          name: product tests and server tarball
      - name: Fix artifact permissions
        run: |
          find . -type f -name \*-executable.jar -exec chmod 0777 {} \;
      - name: Enable impact analysis
        # don't enable this on pushes to master and in PRs in the main repository (not from forks)
        # because these are most often used to run all tests with additional secrets
        if: |
          needs.build-pt.outputs.product-tests-changed == 'false' &&
          github.event_name == 'pull_request' &&
          github.event.pull_request.head.repo.full_name != github.repository &&
          !contains(github.event.pull_request.labels.*.name, 'tests:all') &&
          !contains(github.event.pull_request.labels.*.name, 'tests:all-product')
        run: echo "PTL_OPTS=--impacted-features impacted-features.log" >> $GITHUB_ENV
      - name: Product Tests
        env:
          ABFS_CONTAINER: ${{ secrets.AZURE_ABFS_CONTAINER }}
          ABFS_ACCOUNT: ${{ secrets.AZURE_ABFS_ACCOUNT }}
          ABFS_ACCESS_KEY: ${{ secrets.AZURE_ABFS_ACCESSKEY }}
          S3_BUCKET: ${{ vars.TRINO_S3_BUCKET }}
          AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
          TRINO_AWS_ACCESS_KEY_ID: ${{ secrets.TRINO_AWS_ACCESS_KEY_ID }}
          TRINO_AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
          DATABRICKS_73_JDBC_URL: ${{ secrets.DATABRICKS_73_JDBC_URL }}
          DATABRICKS_91_JDBC_URL: ${{ secrets.DATABRICKS_91_JDBC_URL }}
          DATABRICKS_104_JDBC_URL: ${{ secrets.DATABRICKS_104_JDBC_URL }}
          DATABRICKS_113_JDBC_URL: ${{ secrets.DATABRICKS_113_JDBC_URL }}
          DATABRICKS_122_JDBC_URL: ${{ secrets.DATABRICKS_122_JDBC_URL }}
          DATABRICKS_LOGIN: token
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          GCP_CREDENTIALS_KEY: ${{ secrets.GCP_CREDENTIALS_KEY }}
          GCP_STORAGE_BUCKET: ${{ vars.GCP_STORAGE_BUCKET }}
        run: |
          exec testing/trino-product-tests-launcher/target/trino-product-tests-launcher-*-executable.jar suite run \
            --suite ${{ matrix.suite }} \
            --config config-${{ matrix.config }} \
            ${PTL_OPTS:-} \
            --bind=off --logs-dir logs/ --timeout 2h
      - name: Upload test logs and results
        uses: actions/upload-artifact@v3
        # Upload all test reports only on failure, because the artifacts are large
        if: failure()
        with:
          name: result pt (${{ matrix.config }}, ${{ matrix.suite }}, ${{ matrix.jdk }})
          path: |
            testing/trino-product-tests/target/*
            logs/*
      - name: Upload test report
        uses: actions/upload-artifact@v3
        # Always upload the test report for the annotate.yml workflow,
        # but only the single XML file to keep the artifact small
        if: always()
        with:
          # Name prefix is checked in the `Annotate checks` workflow
          name: test report pt (${{ matrix.config }}, ${{ matrix.suite }}, ${{ matrix.jdk }})
          path: testing/trino-product-tests/target/reports/**/testng-results.xml
          retention-days: ${{ env.TEST_REPORT_RETENTION_DAYS }}
      - name: Update PR check
        uses: ./.github/actions/update-check
        if: >-
          failure() &&
          github.event_name == 'repository_dispatch' &&
          github.event.client_payload.slash_command.args.named.sha != '' &&
          github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha
        with:
          pull_request_number: ${{ github.event.client_payload.pull_request.number }}
          check_name: ${{ github.job }} with secrets
          conclusion: ${{ job.status }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
